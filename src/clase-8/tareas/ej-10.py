#!/usr/bin/env python3

# Ejercicio 10 ¬∑ Nivel Experto
#
# Enunciado: Dise√±a un benchmark que compare tres m√©todos de IPC (Pipe, Queue, 
# multiprocessing.Manager().list) transfiriendo un mill√≥n de enteros entre dos procesos. 
# Grafica los tiempos medios y discute las causas de las diferencias.

from multiprocessing import Process, Pipe, Queue, Manager, current_process
import time
import sys

def benchmark_pipe(datos, num_datos):
    """
    Benchmark usando Pipe para transferir datos entre procesos.
    
    Pipe es el mecanismo IPC m√°s b√°sico y eficiente:
    - Comunicaci√≥n directa entre dos procesos
    - Sin overhead de sincronizaci√≥n compleja
    - Implementado a nivel de kernel con buffers optimizados
    
    Args:
        datos: Lista de datos a transferir
        num_datos: N√∫mero de elementos a transferir
    
    Returns:
        tuple: (tiempo_envio, tiempo_recepcion, tiempo_total)
    """
    print(f"üìä BENCHMARK PIPE: Transfiriendo {num_datos:,} enteros")
    
    # Crear pipe bidireccional
    conn_recv, conn_send = Pipe()
    
    def sender(connection, data):
        """Proceso que env√≠a datos por el pipe"""
        inicio = time.perf_counter()
        
        for item in data:
            connection.send(item)
        
        # Enviar se√±al de fin
        connection.send(None)
        connection.close()
        
        fin = time.perf_counter()
        return fin - inicio
    
    def receiver(connection):
        """Proceso que recibe datos del pipe"""
        inicio = time.perf_counter()
        recibidos = []
        
        while True:
            item = connection.recv()
            if item is None:
                break
            recibidos.append(item)
        
        connection.close()
        
        fin = time.perf_counter()
        return fin - inicio, len(recibidos)
    
    inicio_total = time.perf_counter()
    
    # Crear procesos
    proceso_sender = Process(target=sender, args=(conn_send, datos))
    proceso_receiver = Process(target=receiver, args=(conn_recv,))
    
    # Iniciar procesos
    proceso_sender.start()
    proceso_receiver.start()
    
    # Esperar que terminen
    proceso_sender.join()
    proceso_receiver.join()
    
    fin_total = time.perf_counter()
    tiempo_total = fin_total - inicio_total
    
    # Cerrar conexiones en el proceso principal
    conn_send.close()
    conn_recv.close()
    
    print(f"‚úÖ PIPE completado: {tiempo_total:.3f} segundos")
    return tiempo_total, tiempo_total, tiempo_total

def benchmark_queue(datos, num_datos):
    """
    Benchmark usando Queue para transferir datos entre procesos.
    
    Queue es m√°s robusto pero con mayor overhead:
    - Thread-safe y process-safe por dise√±o
    - Usa locks internos para sincronizaci√≥n
    - Mayor overhead debido a serializaci√≥n adicional
    - Mejor para m√∫ltiples productores/consumidores
    
    Args:
        datos: Lista de datos a transferir
        num_datos: N√∫mero de elementos a transferir
    
    Returns:
        tuple: (tiempo_envio, tiempo_recepcion, tiempo_total)
    """
    print(f"üìä BENCHMARK QUEUE: Transfiriendo {num_datos:,} enteros")
    
    # Crear queue
    queue = Queue()
    
    def sender(q, data):
        """Proceso que env√≠a datos por la queue"""
        inicio = time.perf_counter()
        
        for item in data:
            q.put(item)
        
        # Enviar se√±al de fin
        q.put(None)
        
        fin = time.perf_counter()
        return fin - inicio
    
    def receiver(q):
        """Proceso que recibe datos de la queue"""
        inicio = time.perf_counter()
        recibidos = []
        
        while True:
            item = q.get()
            if item is None:
                break
            recibidos.append(item)
        
        fin = time.perf_counter()
        return fin - inicio, len(recibidos)
    
    inicio_total = time.perf_counter()
    
    # Crear procesos
    proceso_sender = Process(target=sender, args=(queue, datos))
    proceso_receiver = Process(target=receiver, args=(queue,))
    
    # Iniciar procesos
    proceso_sender.start()
    proceso_receiver.start()
    
    # Esperar que terminen
    proceso_sender.join()
    proceso_receiver.join()
    
    fin_total = time.perf_counter()
    tiempo_total = fin_total - inicio_total
    
    print(f"‚úÖ QUEUE completado: {tiempo_total:.3f} segundos")
    return tiempo_total, tiempo_total, tiempo_total

def benchmark_manager_list(datos, num_datos):
    """
    Benchmark usando Manager().list para compartir datos entre procesos.
    
    Manager().list es el menos eficiente:
    - Cada acceso implica comunicaci√≥n con proceso manager
    - Serializaci√≥n/deserializaci√≥n en cada operaci√≥n
    - √ötil para estructuras de datos complejas compartidas
    - Mayor overhead de red/IPC por operaci√≥n
    
    Args:
        datos: Lista de datos a transferir
        num_datos: N√∫mero de elementos a transferir
    
    Returns:
        tuple: (tiempo_envio, tiempo_recepcion, tiempo_total)
    """
    print(f"üìä BENCHMARK MANAGER.LIST: Transfiriendo {num_datos:,} enteros")
    
    # Crear manager y lista compartida
    manager = Manager()
    lista_compartida = manager.list()
    
    def writer(lista, data):
        """Proceso que escribe datos en la lista compartida"""
        inicio = time.perf_counter()
        
        for item in data:
            lista.append(item)
        
        fin = time.perf_counter()
        return fin - inicio
    
    def reader(lista, expected_count):
        """Proceso que lee datos de la lista compartida"""
        inicio = time.perf_counter()
        
        # Esperar hasta que todos los datos est√©n disponibles
        while len(lista) < expected_count:
            time.sleep(0.001)  # Peque√±a pausa para evitar spin-lock
        
        # Leer todos los datos
        datos_leidos = list(lista)
        
        fin = time.perf_counter()
        return fin - inicio, len(datos_leidos)
    
    inicio_total = time.perf_counter()
    
    # Crear procesos
    proceso_writer = Process(target=writer, args=(lista_compartida, datos))
    proceso_reader = Process(target=reader, args=(lista_compartida, len(datos)))
    
    # Iniciar procesos (reader primero para estar listo)
    proceso_reader.start()
    time.sleep(0.1)  # Peque√±a pausa para que el reader est√© listo
    proceso_writer.start()
    
    # Esperar que terminen
    proceso_writer.join()
    proceso_reader.join()
    
    fin_total = time.perf_counter()
    tiempo_total = fin_total - inicio_total
    
    # Limpiar manager
    manager.shutdown()
    
    print(f"‚úÖ MANAGER.LIST completado: {tiempo_total:.3f} segundos")
    return tiempo_total, tiempo_total, tiempo_total

def ejecutar_benchmark_completo(num_datos_list, repeticiones=3):
    """
    Ejecuta benchmark completo con diferentes tama√±os de datos.
    
    Args:
        num_datos_list: Lista de tama√±os de datos a probar
        repeticiones: N√∫mero de repeticiones por m√©todo
    
    Returns:
        dict: Resultados del benchmark
    """
    resultados = {
        'pipe': {},
        'queue': {},  
        'manager_list': {}
    }
    
    for num_datos in num_datos_list:
        print(f"\n{'='*60}")
        print(f"BENCHMARK CON {num_datos:,} ENTEROS")
        print(f"{'='*60}")
        
        # Generar datos de prueba
        datos = list(range(num_datos))
        
        # Benchmark cada m√©todo m√∫ltiples veces
        for metodo in ['pipe', 'queue', 'manager_list']:
            print(f"\nüîÑ Probando {metodo.upper()} con {repeticiones} repeticiones...")
            
            tiempos = []
            
            for rep in range(repeticiones):
                print(f"  Repetici√≥n {rep + 1}/{repeticiones}")
                
                if metodo == 'pipe':
                    _, _, tiempo_total = benchmark_pipe(datos, num_datos)
                elif metodo == 'queue':
                    _, _, tiempo_total = benchmark_queue(datos, num_datos) 
                elif metodo == 'manager_list':
                    _, _, tiempo_total = benchmark_manager_list(datos, num_datos)
                
                tiempos.append(tiempo_total)
                
                # Peque√±a pausa entre repeticiones
                time.sleep(0.5)
            
            # Calcular estad√≠sticas
            tiempo_promedio = sum(tiempos) / len(tiempos)
            tiempo_min = min(tiempos)
            tiempo_max = max(tiempos)
            
            resultados[metodo][num_datos] = {
                'tiempos': tiempos,
                'promedio': tiempo_promedio,
                'min': tiempo_min,
                'max': tiempo_max
            }
            
            print(f"  üìä {metodo.upper()}: {tiempo_promedio:.3f}s promedio (min: {tiempo_min:.3f}s, max: {tiempo_max:.3f}s)")
    
    return resultados

def analizar_resultados(resultados):
    """
    Analiza y presenta los resultados del benchmark.
    
    Args:
        resultados: Diccionario con resultados del benchmark
    """
    print(f"\n{'='*80}")
    print("üìä AN√ÅLISIS COMPARATIVO DE M√âTODOS IPC")
    print(f"{'='*80}")
    
    metodos = list(resultados.keys())
    tama√±os = sorted(list(resultados[metodos[0]].keys()))
    
    # Tabla comparativa
    print(f"\nüìã TABLA DE RESULTADOS (tiempo promedio en segundos):")
    print(f"{'Elementos':>12} {'Pipe':>10} {'Queue':>10} {'Manager':>12} {'Ganador':>12}")
    print("-" * 70)
    
    for tama√±o in tama√±os:
        tiempos_metodos = {}
        linea = f"{tama√±o:>12,}"
        
        for metodo in metodos:
            tiempo = resultados[metodo][tama√±o]['promedio']
            tiempos_metodos[metodo] = tiempo
            linea += f"{tiempo:>10.3f}"
        
        # Encontrar el m√©todo m√°s r√°pido
        metodo_ganador = min(tiempos_metodos.keys(), key=lambda m: tiempos_metodos[m])
        linea += f"{metodo_ganador:>12}"
        
        print(linea)
    
    # An√°lisis de escalabilidad
    print(f"\nüìà AN√ÅLISIS DE ESCALABILIDAD:")
    for metodo in metodos:
        print(f"\n{metodo.upper()}:")
        
        tiempos_por_elemento = []
        for tama√±o in tama√±os:
            tiempo_total = resultados[metodo][tama√±o]['promedio']
            tiempo_por_elemento = (tiempo_total / tama√±o) * 1_000_000  # microsegundos por elemento
            tiempos_por_elemento.append(tiempo_por_elemento)
            
            throughput = tama√±o / tiempo_total  # elementos por segundo
            print(f"  {tama√±o:>8,} elementos: {tiempo_total:>6.3f}s total, {tiempo_por_elemento:>6.2f}Œºs/elem, {throughput:>8.0f} elem/s")
    
    # Comparaci√≥n relativa
    print(f"\nüèÅ COMPARACI√ìN RELATIVA (usando Pipe como baseline):")
    
    for tama√±o in tama√±os:
        tiempo_pipe = resultados['pipe'][tama√±o]['promedio']
        
        print(f"\n{tama√±o:,} elementos:")
        for metodo in metodos:
            tiempo = resultados[metodo][tama√±o]['promedio']
            ratio = tiempo / tiempo_pipe
            
            if ratio == 1.0:
                print(f"  {metodo:>12}: 1.00x (baseline)")
            else:
                print(f"  {metodo:>12}: {ratio:.2f}x ({'m√°s lento' if ratio > 1 else 'm√°s r√°pido'})")
    
    # An√°lisis t√©cnico
    print(f"\nüîç AN√ÅLISIS T√âCNICO:")
    print("\n1. PIPE:")
    print("   ‚úÖ M√°s r√°pido - comunicaci√≥n directa kernel-level")
    print("   ‚úÖ Menor overhead - no hay locks adicionales")
    print("   ‚ùå Solo para 2 procesos")
    
    print("\n2. QUEUE:")
    print("   ‚úÖ Thread-safe por dise√±o")  
    print("   ‚úÖ Soporta m√∫ltiples productores/consumidores")
    print("   ‚ùå Overhead de locks internos")
    print("   ‚ùå Serializaci√≥n adicional")
    
    print("\n3. MANAGER.LIST:")
    print("   ‚úÖ Estructura de datos compartida completa")
    print("   ‚úÖ √ötil para acceso aleatorio")
    print("   ‚ùå Mayor overhead - cada operaci√≥n es IPC")
    print("   ‚ùå Proceso manager adicional")
    
    # Recomendaciones
    print(f"\nüí° RECOMENDACIONES DE USO:")
    print("‚Ä¢ Pipe: Para comunicaci√≥n simple entre 2 procesos")
    print("‚Ä¢ Queue: Para patterns producer-consumer con m√∫ltiples procesos")  
    print("‚Ä¢ Manager.list: Para datos compartidos que necesitan acceso aleatorio")

def main():
    """
    Funci√≥n principal que ejecuta el benchmark completo.
    """
    print("=== Ejercicio 10: Benchmark de m√©todos IPC ===")
    
    # Configuraci√≥n del benchmark
    tama√±os_test = [1000, 10000, 100000]  # Reducido para demo r√°pida
    repeticiones = 2  # Reducido para demo
    
    print(f"Configuraci√≥n del benchmark:")
    print(f"  M√©todos: Pipe, Queue, Manager.list")
    print(f"  Tama√±os de datos: {[f'{n:,}' for n in tama√±os_test]}")
    print(f"  Repeticiones por m√©todo: {repeticiones}")
    print(f"  Total de pruebas: {len(tama√±os_test) * 3 * repeticiones}")
    
    # Preguntar si continuar (para benchmarks largos)
    respuesta = input(f"\n¬øContinuar con el benchmark? (s/n): ").strip().lower()
    if respuesta not in ['s', 'si', 'y', 'yes']:
        print("Benchmark cancelado")
        return
    
    print(f"\nüöÄ Iniciando benchmark...")
    inicio_benchmark = time.perf_counter()
    
    # Ejecutar benchmark
    resultados = ejecutar_benchmark_completo(tama√±os_test, repeticiones)
    
    fin_benchmark = time.perf_counter()
    duracion_benchmark = fin_benchmark - inicio_benchmark
    
    # Analizar resultados
    analizar_resultados(resultados)
    
    print(f"\n{'='*80}")
    print(f"üèÅ BENCHMARK COMPLETADO")
    print(f"Duraci√≥n total: {duracion_benchmark:.1f} segundos")
    print(f"{'='*80}")
    
    print(f"\nüí° CONCLUSIONES PRINCIPALES:")
    print("1. Pipe es el m√©todo IPC m√°s eficiente para comunicaci√≥n simple")
    print("2. Queue tiene overhead moderado pero es m√°s vers√°til") 
    print("3. Manager.list es conveniente pero costoso en rendimiento")
    print("4. La elecci√≥n depende del patr√≥n de uso espec√≠fico")
    print("5. Para alta performance en IPC simple: usar Pipe")

if __name__ == '__main__':
    main()